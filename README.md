#  Sanad-Citation-Network: Paper Topic Prediction in Citation Networks

[View Laderboard](../Leaderboard.html)

## Table of Contents

1. [Challenge Overview](#1-Challenge-Overview)
2. [Dataset](#2-Dataset)
3. [Workflow](#3-Workflow)
4. [Constraints](#4-Constraints)
5. [Repository Structure](#5-Repository-Structure)
6. [Baseline Model GCN](#6-Baseline-Model-GCN)
7. [Secure File Encryption Hybrid RSA AES](#7-Secure-File-Encryption-Hybrid-RSA-AES)
8. [How the Encryption Works](#8-How-the-Encryption-Works)
9. [How Decryption Works](#9-How-Decryption-Works)
10. [Secure Key Handling in GitHub Actions](#10-Secure-Key-Handling-in-GitHub-Actions)
11. [References](#11-References)
---

## 1 Challenge Overview

Welcome to **Sanad Citation Network Challenge!**
This challenge focuses on node classification in a citation network using Graph Neural Networks (GNNs).

Participants are asked to predict the category of scientific papers based solely on the citation graph structure and node features.

Dataset used: PubMed Citation Network (standard benchmark in GNN literature)

### Problem Description

Scientific papers cite other papers, forming a graph where:

|Element           |Description                                    |
|------------------|-----------------------------------------------|
|Nodes             |represent papers                               |
|Edges             |represent citation links                       |
|Node features     |represent paper content (bag-of-words)         |
|Node labels       |represent disease categories                   |

Your Task

Given a paper and its citation neighborhood, predict the disease category of the paper.

This is a semi-supervised node classification task:

Only a subset of nodes are labeled for training

The model must generalize to unseen nodes

### Classes (Disease Categories)

Each paper belongs to one of 3 categories:

| Label | Category |
|-------|----------|
| 0 | Diabetes Mellitus Experimental |
| 1 | Diabetes Mellitus Type 1 |
| 2 | Diabetes Mellitus Type 2 |

### What Makes This Challenging?

**Graph Dependency**:
Papers are not independent â€” predictions rely on citation neighborhoods.

**Homophily Bias**:
Papers often cite papers from the same domain, but not always.

**Limited Labels**:
Only a portion of nodes are labeled for training (60%).

**Over-smoothing Risk**:
Deeper GNNs may degrade performance if not carefully designed.

**No External Information**:
Only graph structure and node features are allowed.

## 2 Dataset
PubMed Citation Network Statistics
|Property |Value|
|---------|------------|
|Nodes |19,717 papers|
|Edges |88,648 citation links|
|Node Features |500|
|Classes |3|
|Graph Type| Homogeneous|

### Data Format

The dataset is provided as preprocessed PyTorch tensors:

```python
import torch

# Load raw data
features = torch.load('data/raw/features.pt')    # [19717, 500]
edges = torch.load('data/raw/edges.pt')           # [2, 88648]
labels = torch.load('data/raw/labels.pt')         # [19717]

# Load masks
train_mask = torch.load('data/splits/train_mask.pt')
val_mask = torch.load('data/splits/val_mask.pt')
test_mask = torch.load('data/splits/test_mask.pt')
```
Using features.pt, edges.pt, labels.pt, and masks:

1.Makes your GNN easy to implement

2.Efficient in memory

3.Compatible with PyG functions

4.Handles semi-supervised masking cleanly

5.Supports batching / inductive learning

6.Improves reproducibility and standardization
### Split Information

| Split | Nodes | Ratio |
|-------|-------|-------|
| Training | 11,829 | 60% |
| Validation | 3,942 | 20% |
| Test | 3,946 | 20% |

# Dataset & Private Files

The challenge uses private files for evaluation:

Submission file: submission.private.csv

Test labels: test_labels_hidden.private.pt

These files are hosted on Hugging Face and linked to this repository.

Private files are used internally for scoring and leaderboard computation; they are not included in the repository.

## 3 Workflow

Data Processing: Load node features, adjacency information, and graph structure.

Model Training:

GCN model with hidden layers (ReLU + dropout)

Output layer computes log softmax for node classification

[prepare_dataset.py]  -->  data/raw/, data/splits/, data/processed/
                                  |
                                  v
[starter_code/baseline.py]  -->  Train a GCN model  -->  results/best_model.pt
                                                                |
                                                                v
[starter_code/generate_submission.py]  -->  submissions/submission.private.csv
                                                      |
                                                      v
[scoring_script.py]  -->  Compare predictions vs hidden test labels  -->  leaderboard.json
                                                                              |
                                                                              v
[update_leaderboard.py]  -->  leaderboard.md
                                    |
                                    v
[.github/workflows/score.yml]  -->  Automates scoring on PRs

### Evaluation Metric
| Metric                | Split            | Purpose                             | Definition                                                                                  |
| --------------------- | ---------------- | ----------------------------------- | ------------------------------------------------------------------------------------------- |
| Accuracy              | train, val, test | Overall node prediction correctness | Fraction of correctly predicted nodes out of all nodes in the split: `Accuracy = #correct_predictions / total_nodes` |
| Weighted F1           | train, val, test | Class-balanced node performance     | Harmonic mean of precision and recall, averaged across classes weighted by class size: `F1 = 2 * (Precision * Recall) / (Precision + Recall)` |
| Loss (NLL)            | train            | Optimization, early stopping        | Negative log-likelihood loss for classification: `NLL Loss = - (1/N) * sum_i y_i * log(y_hat_i)`, applied only on training nodes |
| Classification report | test             | Detailed per-class performance      | Shows **precision, recall, F1-score, and support** for each class separately; provides fine-grained insight for imbalanced classes. |
                                                                                              
Baseline Performance

| Model | Accuracy |
|-------|----------|
| Random Guess | ~33% |
| 2-layer GCN | ~78% |
| Target | 80%+ |

## 4 Constraints

**To ensure fairness and pedagogical value**:

**No External Data**:
Use only the PubMed dataset.

**Graph Features Only**:
No handcrafted or text-based features beyond provided node features.

**CPU Training Only**:
Models must be trainable on CPU.

**Must Use GNNs**
At least one message-passing layer (GCN, GraphSAGE, GAT, etc.).

## Quick Start

### Install Dependencies
```bash
pip install -r starter_code/requirements.txt
```

### Train the Baseline
```bash
python starter_code/baseline.py --epochs 200
```

This trains a 2-layer GCN model, saves the best checkpoint to `results/best_model.pt`, and generates `submissions/submission.private.csv`.

### Generate a Submission
```bash
python starter_code/generate_submission.py --model-path results/best_model.pt
```

### Score a Submission
```bash
python scoring_script.py submissions/submission.private.csv
```




## 5 Repository Structure

```
gnn/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # Raw graph data
â”‚   â”‚   â”œâ”€â”€ features.pt               # Node feature matrix [19717, 500]
â”‚   â”‚   â”œâ”€â”€ edges.pt                  # Edge index [2, 88648]
â”‚   â”‚   â”œâ”€â”€ labels.pt                 # All node labels [19717]
â”‚   â”‚   â””â”€â”€ metadata.json             # Dataset metadata (counts, class names, etc.)
â”‚   â”‚
â”‚   â”œâ”€â”€ splits/                       # Train/val/test masks
â”‚   â”‚   â”œâ”€â”€ train_mask.pt             # Boolean mask: which nodes are training
â”‚   â”‚   â”œâ”€â”€ val_mask.pt               # Boolean mask: which nodes are validation
â”‚   â”‚   â””â”€â”€ test_mask.pt              # Boolean mask: which nodes are test
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                    # Processed label files
â”‚   â”‚   â”œâ”€â”€ train_labels.pt           # Labels with -1 for non-training nodes
â”‚   â”‚   â”œâ”€â”€ val_labels.pt             # Labels with -1 for non-validation nodes
|   |   â”œâ”€â”€ test_labels_hidden.enc       # Label with -1 for non-test nodes encripted (for scoring)
â”‚   â”‚   â””â”€â”€ test_labels_hidden.private.pt     # Labels with -1 for non-test nodes (for scoring)
â”‚   â”‚
â”‚   â””â”€â”€ README.md                     # Data documentation
â”‚
â”œâ”€â”€ starter_code/
â”‚   â”œâ”€â”€ baseline.py                   # GCN training script (PyTorch Geometric)
â”‚   â”œâ”€â”€ generate_submission.py        # Generate submission CSV from trained model
â”‚   â””â”€â”€ requirements.txt              # Python dependencies (NEW - was missing)
â”‚
â”œâ”€â”€ submissions/                      # Where submission CSV files go
â”‚   â”œâ”€â”€ submission.private.csv        # A submission file (gitignored)
â”‚   â””â”€â”€ sample_submission.private.enc # Sample submission encripted (private)
â”‚
â”œâ”€â”€ prepare_dataset.py                # Downloads PubMed and creates data/ structure
â”œâ”€â”€ scoring_script.py                 # Scores a submission CSV against ground truth
â”œâ”€â”€ update_leaderboard.py             # Generates leaderboard.md from leaderboard.json
â”œâ”€â”€ leaderboard.json                  # Machine-readable leaderboard data
â”œâ”€â”€ leaderboard.md                    # Human-readable leaderboard table
â”œâ”€â”€ Leaderboard.html                  # HTML version of leaderboard
â”œâ”€â”€ README.md                         # Project overview and instructions
â””â”€â”€ .github/workflows/score.yml       # CI: auto-scores on PR submissions
```
## 6 Baseline Model GCN 
### Overview

The script implements a Graph Convolutional Network (GCN) baseline for node classification on a graph dataset (in your example, the PubMed dataset). It handles data loading, training, evaluation, and test predictions, producing a CSV submission file. The design follows standard geometric deep learning practices.


### 1. Data Input

Dataset: Nodes represent entities (e.g., PubMed papers), edges represent connections (e.g., citation links).

Node features: Continuous vectors for each node (e.g., 2D or more depending on dataset).

Masks: Boolean masks for training, validation, and test splits.

Data loader (PubMedDataLoader) loads all tensors (features, edges, labels) and moves them to GPU/CPU.

### 2. Model Architecture

GCN layers: Default 2 layers (num_layers=2), each using GCNConv.

Forward pass:

Hidden layers: ReLU activation + dropout.

Output layer: Log softmax over classes.

Output: Node-level log probabilities for classification.

Training settings:

Optimizer: Adam

Loss: Negative log likelihood (F.nll_loss) over training nodes only

Regularization: Dropout + weight decay

Early stopping monitored via validation accuracy.

### 3. Training & Evaluation

Epoch loop:

Forward + backward pass on training nodes.

Evaluate on training and validation masks.

Save best model based on validation accuracy.

Early stopping if validation accuracy does not improve.

Metrics:

Accuracy

Weighted F1

Classification report per class

### 4. Submission

After training, predictions on test nodes are saved in a CSV (submissions/submission.private.csv) with columns: node_id, target.

Helper function save_submission_csv handles formatting and preview.

### 5. Key Points / Features

Modular design: GCN class separated from data loading.

Device agnostic: Automatically uses GPU if available.

Configurable via CLI arguments (--hidden-channels, --num-layers, --dropout, --epochs, etc.).

Provides detailed logs of loss, train/val accuracy, best epoch, and final test results.

Ready for extension to other datasets or graph-level tasks.
### 6 Mental map of the GCN code
```
features.pt  â†’ initial embeddings (x)
edges.pt     â†’ adjacency matrix (edge_index)

x, edge_index
     â†“
GCNConv layer 1
     â†“
hidden embedding
     â†“
GCNConv layer 2
     â†“
final embedding
     â†“
log_softmax â†’ predictions
```

### 7 Starter Model (GCN Baseline)

```python
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv

class GCN(nn.Module):
    def __init__(self, num_features, hidden_channels, num_classes, num_layers=2, dropout=0.5):
        super(GCN, self).__init__()
        self.convs = nn.ModuleList()
        self.convs.append(GCNConv(num_features, hidden_channels))
        for _ in range(num_layers - 2):
            self.convs.append(GCNConv(hidden_channels, hidden_channels))
        self.convs.append(GCNConv(hidden_channels, num_classes))
        self.dropout = dropout
        self.num_layers = num_layers

    def forward(self, x, edge_index):
        for i in range(self.num_layers - 1):
            x = self.convs[i](x, edge_index)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.convs[-1](x, edge_index)
        return F.log_softmax(x, dim=1)
```

## 7 Secure File Encryption Hybrid RSA AES

To ensure privacy and prevent unauthorized access to hidden labels and private submissions, this repository uses hybrid encryption combining AES and RSA.

Why Hybrid Encryption?

AES (Advanced Encryption Standard) â†’ Fast and efficient for encrypting large files.

RSA (Asymmetric Encryption) â†’ Securely encrypts the AES key.

Combining both provides:

High performance (AES)

Secure key exchange (RSA)

## 8 How the Encryption Works

When a file is encrypted:

A random AES key is generated.

The file is encrypted using AES (CBC mode).

The AES key is encrypted using RSA (OAEP + SHA256).

The final encrypted file structure is:

[4 bytes: RSA key length]
[RSA-encrypted AES key]
[16 bytes IV]
[AES-encrypted data]

## 9 How Decryption Works

During scoring, files are automatically decrypted using the private RSA key:

def decrypt_file_rsa_aes(input_file, output_file, private_key_file):
    """Decrypt a file that was encrypted with hybrid AES + RSA."""
    with open(private_key_file, "rb") as f:
        private_key = serialization.load_pem_private_key(f.read(), password=None)

    with open(input_file, "rb") as f:
        # Read length of RSA-encrypted AES key
        key_len_bytes = f.read(4)
        key_len = int.from_bytes(key_len_bytes, "big")

        # Read RSA-encrypted AES key
        encrypted_aes_key = f.read(key_len)

        # Decrypt AES key using RSA
        aes_key = private_key.decrypt(
            encrypted_aes_key,
            asym_padding.OAEP(
                mgf=asym_padding.MGF1(algorithm=hashes.SHA256()),
                algorithm=hashes.SHA256(),
                label=None
            )
        )

        # Read IV and encrypted content
        iv = f.read(16)
        encrypted_data = f.read()

    # AES decryption
    cipher = Cipher(algorithms.AES(aes_key), modes.CBC(iv), backend=default_backend())
    decryptor = cipher.decryptor()
    decrypted_padded = decryptor.update(encrypted_data) + decryptor.finalize()

    # Remove PKCS7 padding
    unpadder = padding.PKCS7(128).unpadder()
    decrypted_data = unpadder.update(decrypted_padded) + unpadder.finalize()

    with open(output_file, "wb") as f:
        f.write(decrypted_data)

    print(f"Decrypted {input_file} â†’ {output_file}")
### ðŸ§  Automatic Decryption During Scoring

When running:

python scoring_script.py submissions/file.csv

The script automatically detects encrypted files (.enc) and decrypts them before evaluation:

submission_file = sys.argv[1]

if submission_file.endswith(".enc"):
    decrypted_submission = submission_file.replace(".enc", ".csv")
    decrypt_file_rsa_aes(submission_file, decrypted_submission, "private_key.pem")
    submission_file = decrypted_submission

Hidden test labels are also decrypted automatically if needed.

## 10 Secure Key Handling in GitHub Actions

The private RSA key is never stored in the repository.

Instead:

The private key is stored as a GitHub Secret (PRIVATE_KEY)

It is Base64-encoded

It is restored during CI execution

GitHub Actions Workflow
- name: Restore PEM key
  run: |
    echo "${{ secrets.PRIVATE_KEY }}" | base64 -d > private_key.pem
    chmod 600 private_key.pem

- name: Run scoring
  run: python scoring_script.py submissions/submission.private.enc
Why This Is Secure

The private key exists only during CI execution

It is never committed to GitHub

File permissions are restricted (chmod 600)

Encrypted files can safely be stored in the repository

## 11 References

- Kipf, T. N., & Welling, M. (2017). **Semi-Supervised Classification with Graph Convolutional Networks**. [arXiv:1609.02907](https://arxiv.org/abs/1609.02907)  
- Official GitHub repository for the paper: [https://github.com/tkipf/pygcn](https://github.com/tkipf/pygcn)
- **GNNs**: [Basira Lab youtube](https://www.youtube.com/playlist?list=PLug43ldmRSo14Y_vt7S6vanPGh-JpHR7T)
